{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento de los datos\n",
    "#### http://ai.stanford.edu/~amaas/data/sentiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import keras\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_data_txt(file_path):\n",
    "    _file = open(file_path,'r')\n",
    "    data = _file.read()\n",
    "    symbols = re.compile(r'[!\"#$%&\\()*+,-./:;<=>?@\\[\\]\\\\^_`{|}~]')\n",
    "    clean_data = symbols.sub('', data)\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_to_lists(files_path,label):\n",
    "    files = os.listdir(files_path)\n",
    "    data = []\n",
    "    for _file in files:\n",
    "        data.append(get_data_txt(files_path+'/'+_file))\n",
    "    labels = [label]*len(data)\n",
    "    \n",
    "    return (data,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_csv(comments,labels,name):\n",
    "    data = {'comments': comments, 'labels':labels}\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    df.to_csv(name,sep=',', index=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "neg_train = dir_to_lists('/home/josh/MEGA/U_S_VII/Ingenieria_del_conocimiento/Proyecto/dataset/aclImdb/train/neg',0)\n",
    "pos_train = dir_to_lists('/home/josh/MEGA/U_S_VII/Ingenieria_del_conocimiento/Proyecto/dataset/aclImdb/train/pos',1)\n",
    "neg_test = dir_to_lists('/home/josh/MEGA/U_S_VII/Ingenieria_del_conocimiento/Proyecto/dataset/aclImdb/test/neg',0)\n",
    "pos_test = dir_to_lists('/home/josh/MEGA/U_S_VII/Ingenieria_del_conocimiento/Proyecto/dataset/aclImdb/train/pos',1)\n",
    "\n",
    "\n",
    "data = pos_train[0]+neg_train[0]+pos_test[0]+neg_test[0]\n",
    "labels = pos_train[1]+neg_train[1]+pos_test[1]+neg_test[1]\n",
    "\n",
    "df = data_to_csv(data,labels,'./train2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = keras.datasets.imdb.get_word_index()\n",
    "\n",
    "def get_indices_from_review(review):\n",
    "    regex = re.compile(r'[!\"#$%&\\()*+,-./:;<=>?@\\[\\]\\\\^_`{|}~]')\n",
    "    s = regex.sub('', review)\n",
    "    # 2 is \"unknown\"\n",
    "    sequence = map(lambda word: word_index.get(word, 2) + 3, s.lower().split())\n",
    "    sequence = map(lambda index: 2 if index >= 30000 else index, sequence)\n",
    "    # 1 is \"start of sequence\"\n",
    "    return [1] + list(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequences(sequences, dim):\n",
    "    vec = np.zeros(shape=(len(sequences), dim), dtype=np.float32)\n",
    "    for i, seq in enumerate(sequences):\n",
    "        vec[i, seq] = 1\n",
    "    return vec\n",
    "#vectorize_sequences([[1,5,2],[7,1,2],[9,5,2]],dim=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 18)                540018    \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 16)                304       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 540,339\n",
      "Trainable params: 540,339\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_no_drop = keras.Sequential([\n",
    "  keras.layers.Dense(units=18, activation='relu', input_shape=(30000,)),\n",
    "  keras.layers.Dense(units=16, activation='relu'),\n",
    "  keras.layers.Dense(units=1, activation='sigmoid')\n",
    "], name='comments_review')\n",
    "model_no_drop.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./train2.csv')\n",
    "x = data['comments']\n",
    "y = data['labels']\n",
    "\n",
    "x_index = []\n",
    "for i in x:\n",
    "    x_index.append(get_indices_from_review(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = vectorize_sequences(x_index,dim=30000)\n",
    "y_ = np.expand_dims(np.asarray(y, dtype=np.float32), axis=-1)\n",
    "x_train,x_val,y_train, y_val = train_test_split(x_,y_,test_size=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 14s 687us/step - loss: 0.3393 - acc: 0.8587 - val_loss: 0.3086 - val_acc: 0.8754\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 12s 598us/step - loss: 0.1306 - acc: 0.9546 - val_loss: 0.3318 - val_acc: 0.8816\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 12s 601us/step - loss: 0.0637 - acc: 0.9797 - val_loss: 0.4216 - val_acc: 0.8780\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 12s 597us/step - loss: 0.0319 - acc: 0.9910 - val_loss: 0.5733 - val_acc: 0.8666\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 12s 597us/step - loss: 0.0223 - acc: 0.9928 - val_loss: 0.7210 - val_acc: 0.8566\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 12s 606us/step - loss: 0.0266 - acc: 0.9906 - val_loss: 0.6658 - val_acc: 0.8600\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 12s 606us/step - loss: 0.0209 - acc: 0.9924 - val_loss: 0.7283 - val_acc: 0.8644\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 12s 605us/step - loss: 0.0098 - acc: 0.9969 - val_loss: 0.8508 - val_acc: 0.8656\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 12s 609us/step - loss: 0.0071 - acc: 0.9974 - val_loss: 0.8722 - val_acc: 0.8656\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 12s 612us/step - loss: 0.0042 - acc: 0.9985 - val_loss: 0.9431 - val_acc: 0.8686\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 12s 610us/step - loss: 0.0105 - acc: 0.9964 - val_loss: 0.8799 - val_acc: 0.8634\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 12s 604us/step - loss: 0.0115 - acc: 0.9965 - val_loss: 0.9195 - val_acc: 0.8628\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 12s 604us/step - loss: 0.0065 - acc: 0.9979 - val_loss: 0.9567 - val_acc: 0.8636\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 12s 602us/step - loss: 0.0027 - acc: 0.9994 - val_loss: 1.0547 - val_acc: 0.8638\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 12s 604us/step - loss: 9.0923e-04 - acc: 0.9999 - val_loss: 1.0929 - val_acc: 0.8638\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 12s 607us/step - loss: 9.8358e-04 - acc: 1.0000 - val_loss: 1.1326 - val_acc: 0.8650\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 12s 612us/step - loss: 8.8785e-04 - acc: 1.0000 - val_loss: 1.1590 - val_acc: 0.8636\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 12s 608us/step - loss: 8.6172e-04 - acc: 1.0000 - val_loss: 1.1830 - val_acc: 0.8644\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 12s 612us/step - loss: 8.4413e-04 - acc: 1.0000 - val_loss: 1.2057 - val_acc: 0.8654\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 12s 610us/step - loss: 8.3146e-04 - acc: 1.0000 - val_loss: 1.2251 - val_acc: 0.8656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feae03cf470>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_no_drop.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model_no_drop.fit(x_train, y_train,\n",
    "          epochs=20, batch_size=32,\n",
    "          validation_data=(x_val, y_val),\n",
    "          callbacks=[keras.callbacks.TensorBoard(log_dir='logs_comments_review')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. ... 0. 0. 0.]]\n",
      "test: 0.0000%\n"
     ]
    }
   ],
   "source": [
    "review = \"\"\"I disagree in calling this a stoner movie just because weed also makes an appearance. I can't imagine this as even approaching \"stoner classic.\" That would be like calling Singles a \"grunge film.\" The movie definitely plods along with a murky plot. At times I wondered if the script had either been dropped and shuffled or if they lost it entirely and just tried to wing it. Watching this movie reminded me of watching children play-acting and making the story up as they go along.<br /><br />The characters are wooden, the dialog is taxed, and the whole story seems to be completely disconnected. Who got killed? When? What? And this is how you act when your friend overdoses? Complete lack of emotion and utter disconnect from reality.<br /><br />As for the droning guitar soundtrack that accompanies each scene: enough! It was like watching the opening menu screen where the same track loops endlessly in the background, neither moving forward or back.<br /><br />I kept watching and hoping that the plot would somehow fall in to order, the acting and dialog would improve or something, somehow would focus this mess in to a coherent movie. After 112 minutes, it never happened\"\"\"\n",
    "review_vec = get_indices_from_review(review)\n",
    "vec = vectorize_sequences([review_vec], dim=30000)\n",
    "print(vec)\n",
    "res = np.squeeze(model_no_drop.predict(vec))\n",
    "print('test: {:.4f}%'.format(res * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 18)                540018    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                304       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 540,339\n",
      "Trainable params: 540,339\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "  keras.layers.Dense(units=18, activation='relu', input_shape=(30000,)),\n",
    "  keras.layers.Dropout(0.7),\n",
    "  keras.layers.Dense(units=16, activation='relu'),\n",
    "  keras.layers.Dropout(0.7),\n",
    "  keras.layers.Dense(units=1, activation='sigmoid')\n",
    "], name='with_dropout')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 7s 336us/step - loss: 0.6494 - acc: 0.6186 - val_loss: 0.5533 - val_acc: 0.8528\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 6s 296us/step - loss: 0.5734 - acc: 0.7119 - val_loss: 0.4696 - val_acc: 0.8682\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 6s 302us/step - loss: 0.5153 - acc: 0.7723 - val_loss: 0.4021 - val_acc: 0.8770\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 6s 297us/step - loss: 0.4735 - acc: 0.8009 - val_loss: 0.3831 - val_acc: 0.8788\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 6s 297us/step - loss: 0.4354 - acc: 0.8287 - val_loss: 0.3532 - val_acc: 0.8800\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 6s 303us/step - loss: 0.4069 - acc: 0.8474 - val_loss: 0.3365 - val_acc: 0.8802\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 6s 306us/step - loss: 0.3733 - acc: 0.8655 - val_loss: 0.3260 - val_acc: 0.8806\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 6s 310us/step - loss: 0.3545 - acc: 0.8778 - val_loss: 0.3403 - val_acc: 0.8846\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 6s 308us/step - loss: 0.3411 - acc: 0.8801 - val_loss: 0.3302 - val_acc: 0.8792\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 6s 303us/step - loss: 0.3171 - acc: 0.8889 - val_loss: 0.3357 - val_acc: 0.8786\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 6s 306us/step - loss: 0.3019 - acc: 0.8965 - val_loss: 0.3666 - val_acc: 0.8800\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 6s 306us/step - loss: 0.2867 - acc: 0.9011 - val_loss: 0.3592 - val_acc: 0.8748\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 6s 305us/step - loss: 0.2880 - acc: 0.9017 - val_loss: 0.3875 - val_acc: 0.8758\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 6s 313us/step - loss: 0.2777 - acc: 0.9064 - val_loss: 0.3918 - val_acc: 0.8766\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 6s 285us/step - loss: 0.2644 - acc: 0.9118 - val_loss: 0.4022 - val_acc: 0.8758\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 6s 285us/step - loss: 0.2628 - acc: 0.9140 - val_loss: 0.4187 - val_acc: 0.8738\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 6s 307us/step - loss: 0.2539 - acc: 0.9160 - val_loss: 0.4451 - val_acc: 0.8700\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 6s 299us/step - loss: 0.2476 - acc: 0.9189 - val_loss: 0.4375 - val_acc: 0.8720\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 6s 309us/step - loss: 0.2474 - acc: 0.9181 - val_loss: 0.4501 - val_acc: 0.8710\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 6s 308us/step - loss: 0.2409 - acc: 0.9191 - val_loss: 0.4675 - val_acc: 0.8680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feae1200128>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=20, batch_size=512,\n",
    "          validation_data=(x_val, y_val),\n",
    "          callbacks=[keras.callbacks.TensorBoard(log_dir='logs_dropout')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. ... 0. 0. 0.]]\n",
      "test: 0.4957%\n"
     ]
    }
   ],
   "source": [
    "review = \"\"\"I disagree in calling this a stoner movie just because weed also makes an appearance. I can't imagine this as even approaching \"stoner classic.\" That would be like calling Singles a \"grunge film.\" The movie definitely plods along with a murky plot. At times I wondered if the script had either been dropped and shuffled or if they lost it entirely and just tried to wing it. Watching this movie reminded me of watching children play-acting and making the story up as they go along.<br /><br />The characters are wooden, the dialog is taxed, and the whole story seems to be completely disconnected. Who got killed? When? What? And this is how you act when your friend overdoses? Complete lack of emotion and utter disconnect from reality.<br /><br />As for the droning guitar soundtrack that accompanies each scene: enough! It was like watching the opening menu screen where the same track loops endlessly in the background, neither moving forward or back.<br /><br />I kept watching and hoping that the plot would somehow fall in to order, the acting and dialog would improve or something, somehow would focus this mess in to a coherent movie. After 112 minutes, it never happened\"\"\"\n",
    "review_vec = get_indices_from_review(review)\n",
    "vec = vectorize_sequences([review_vec], dim=30000)\n",
    "print(vec)\n",
    "res = np.squeeze(model.predict(vec))\n",
    "print('test: {:.4f}%'.format(res * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "num_words = 5000\n",
    "(train_data, train_labels), (test_data, test_labels) = keras.datasets.imdb.load_data(num_words=num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels[0])\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 1s 1us/step\n"
     ]
    }
   ],
   "source": [
    "word_index = keras.datasets.imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
