{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento de los datos\n",
    "#### http://ai.stanford.edu/~amaas/data/sentiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "def get_data_txt(file_path):\n",
    "    _file = open(file_path,'r')\n",
    "    data = _file.read()\n",
    "    symbols = re.compile(r'[!\"#$%&\\()*+,-./:;<=>?@\\[\\]\\\\^_`{|}~]')\n",
    "    clean_data = symbols.sub('', data)\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_to_lists(files_path,label):\n",
    "    files = os.listdir(files_path)\n",
    "    data = []\n",
    "    for _file in files:\n",
    "        data.append(get_data_txt(files_path+'/'+_file))\n",
    "    labels = [label]*len(data)\n",
    "    \n",
    "    return (data,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_csv(comments,labels,name):\n",
    "    data = {'comments': comments, 'labels':labels}\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    df.to_csv(name,sep=',', index=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "neg = dir_to_lists('/home/josh/MEGA/U_S_VII/Ingenieria_del_conocimiento/Proyecto/dataset/aclImdb/train/neg',0)\n",
    "pos = dir_to_lists('/home/josh/MEGA/U_S_VII/Ingenieria_del_conocimiento/Proyecto/dataset/aclImdb/train/pos',1)\n",
    "\n",
    "data = pos[0]+neg[0]\n",
    "labels = pos[1]+neg[1]\n",
    "\n",
    "df = data_to_csv(data,labels,'./train2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = keras.datasets.imdb.get_word_index()\n",
    "\n",
    "def get_indices_from_review(review):\n",
    "    regex = re.compile(r'[!\"#$%&\\()*+,-./:;<=>?@\\[\\]\\\\^_`{|}~]')\n",
    "    s = regex.sub('', review)\n",
    "    # 2 is \"unknown\"\n",
    "    sequence = map(lambda word: word_index.get(word, 2) + 3, s.lower().split())\n",
    "    sequence = map(lambda index: 2 if index >= 30000 else index, sequence)\n",
    "    # 1 is \"start of sequence\"\n",
    "    return [1] + list(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 1., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vectorize_sequences(sequences, dim):\n",
    "    vec = np.zeros(shape=(len(sequences), dim), dtype=np.float32)\n",
    "    for i, seq in enumerate(sequences):\n",
    "        vec[i, seq] = 1\n",
    "    return vec\n",
    "vectorize_sequences([[1,5,2],[7,1,2],[9,5,2]],dim=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 18)                540018    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                304       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 540,339\n",
      "Trainable params: 540,339\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "  keras.layers.Dense(units=18, activation='relu', input_shape=(30000,)),\n",
    "  keras.layers.Dense(units=16, activation='relu'),\n",
    "  keras.layers.Dense(units=1, activation='sigmoid')\n",
    "], name='comments_review')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./train2.csv')\n",
    "x = data['comments']\n",
    "y = data['labels']\n",
    "\n",
    "x_index = []\n",
    "for i in x:\n",
    "    x_index.append(get_indices_from_review(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorize_sequences(x_index,dim=30000)\n",
    "y_train = np.expand_dims(np.asarray(y, dtype=np.float32), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/josh/.local/lib/python3.5/site-packages/sklearn/externals/joblib/_multiprocessing_helpers.py:38: UserWarning: [Errno 12] Cannot allocate memory.  joblib will operate in serial mode\n",
      "  warnings.warn('%s.  joblib will operate in serial mode' % (e,))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 12s 461us/step - loss: 0.4447 - acc: 0.8242\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 6s 258us/step - loss: 0.2345 - acc: 0.9211\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 6s 256us/step - loss: 0.1622 - acc: 0.9465\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 6s 258us/step - loss: 0.1217 - acc: 0.9598\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 6s 255us/step - loss: 0.0943 - acc: 0.9693\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 7s 274us/step - loss: 0.0708 - acc: 0.9788\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 6s 252us/step - loss: 0.0530 - acc: 0.9854\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 6s 250us/step - loss: 0.0398 - acc: 0.9884\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 7s 262us/step - loss: 0.0291 - acc: 0.9923\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 6s 253us/step - loss: 0.0208 - acc: 0.9951\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 6s 250us/step - loss: 0.0140 - acc: 0.9971\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 6s 247us/step - loss: 0.0097 - acc: 0.9980\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 6s 247us/step - loss: 0.0075 - acc: 0.9985\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 6s 256us/step - loss: 0.0039 - acc: 0.9993\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 6s 259us/step - loss: 0.0034 - acc: 0.9993\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 6s 253us/step - loss: 0.0030 - acc: 0.9993\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 6s 254us/step - loss: 7.8907e-04 - acc: 1.0000\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 6s 257us/step - loss: 0.0014 - acc: 0.9997\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 6s 254us/step - loss: 3.3291e-04 - acc: 1.0000\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 6s 253us/step - loss: 0.0012 - acc: 0.9996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f240b489f28>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=20, batch_size=32,\n",
    "          callbacks=[keras.callbacks.TensorBoard(log_dir='logs_comments_review')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. ... 0. 0. 0.]]\n",
      "test: 76.7952%\n"
     ]
    }
   ],
   "source": [
    "review = \"\"\"the special effects was not incredible\"\"\"\n",
    "review_vec = get_indices_from_review(review)\n",
    "vec = vectorize_sequences([review_vec], dim=30000)\n",
    "print(vec)\n",
    "res = np.squeeze(model.predict(vec))\n",
    "print('test: {:.4f}%'.format(res * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 18)                540018    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 16)                304       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 540,339\n",
      "Trainable params: 540,339\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "  keras.layers.Dense(units=18, activation='relu', input_shape=(30000,)),\n",
    "  keras.layers.Dropout(0.7),\n",
    "  keras.layers.Dense(units=16, activation='relu'),\n",
    "  keras.layers.Dropout(0.7),\n",
    "  keras.layers.Dense(units=1, activation='sigmoid')\n",
    "], name='with_dropout')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 7s 271us/step - loss: 0.6509 - acc: 0.6532\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 7s 265us/step - loss: 0.5813 - acc: 0.7742\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 7s 262us/step - loss: 0.5367 - acc: 0.8175\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 7s 270us/step - loss: 0.5028 - acc: 0.8416\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 7s 279us/step - loss: 0.4682 - acc: 0.8504\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 7s 267us/step - loss: 0.4403 - acc: 0.8591\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 7s 278us/step - loss: 0.4179 - acc: 0.8697\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 7s 295us/step - loss: 0.3949 - acc: 0.8753\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 7s 297us/step - loss: 0.3847 - acc: 0.8778\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 8s 303us/step - loss: 0.3771 - acc: 0.8770\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 7s 280us/step - loss: 0.3625 - acc: 0.8815\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 7s 274us/step - loss: 0.3520 - acc: 0.8824\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 7s 269us/step - loss: 0.3424 - acc: 0.8864\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 7s 266us/step - loss: 0.3302 - acc: 0.8893\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 7s 270us/step - loss: 0.3228 - acc: 0.8927\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 7s 264us/step - loss: 0.3105 - acc: 0.8968\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 7s 275us/step - loss: 0.3014 - acc: 0.9014\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 7s 277us/step - loss: 0.2952 - acc: 0.9030\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 7s 275us/step - loss: 0.2890 - acc: 0.9069\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 7s 277us/step - loss: 0.2869 - acc: 0.9082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f262439e908>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=20, batch_size=512,\n",
    "          callbacks=[keras.callbacks.TensorBoard(log_dir='logs_dropout')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. ... 0. 0. 0.]]\n",
      "test: 99.8589%\n"
     ]
    }
   ],
   "source": [
    "review = \"\"\"I do not like cartoons. When I was a child, I preferred reading and drawing to watching television, cartoons included–which makes the fact that I am a movie reviewer somewhat ironic. Anyways, cartoons always felt boring to me: unrealistic colorful characters talking and acting like real people looked too far-fetched to relax and enjoy. Be it the hysterical madness of old Looney Tunes, Disney’s cheesy fairy tales, or Pixar’s 3D family movies, to me it is all the same. I guess you can picture me as an arrogant, heartless cartoon hater. Which I am not, but whatever.\"\"\"\n",
    "review_vec = get_indices_from_review(review)\n",
    "vec = vectorize_sequences([review_vec], dim=30000)\n",
    "print(vec)\n",
    "res = np.squeeze(model.predict(vec))\n",
    "print('test: {:.4f}%'.format(res * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "num_words = 5000\n",
    "(train_data, train_labels), (test_data, test_labels) = keras.datasets.imdb.load_data(num_words=num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels[0])\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 1s 1us/step\n"
     ]
    }
   ],
   "source": [
    "word_index = keras.datasets.imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
